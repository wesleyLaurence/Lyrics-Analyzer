{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Music Lyrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "# classes\n",
    "from lyrics_tool import Lyrics_Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "use pandas to read csv files from directory\n",
    "join all datasets into final df variable\n",
    "\"\"\"\n",
    "dataset_folder_path = 'datasets/'\n",
    "\n",
    "dataset_1 = pd.read_csv(dataset_folder_path+'top2018.csv')[['name','artists']]\n",
    "dataset_1.columns = ['name','artist']\n",
    "\n",
    "dataset_2 = pd.read_csv(dataset_folder_path+'top50.csv',encoding='latin-1')[['Track.Name','Artist.Name']]\n",
    "dataset_2.columns = ['name','artist']\n",
    "\n",
    "dataset_3 = pd.read_csv(dataset_folder_path+'data.csv')[['song_title','artist']]\n",
    "dataset_3.columns = ['name','artist']\n",
    "\n",
    "dataset_4 = pd.read_csv(dataset_folder_path+'top10s.csv',encoding='latin-1')[['title','artist']]\n",
    "dataset_4.columns = ['name','artist']\n",
    "\n",
    "# join datasets together into one master dataframe\n",
    "df = pd.concat([dataset_1, dataset_2,dataset_3,dataset_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clean data\n",
    "remove parentheses to prevent problems with genius API\n",
    "\"\"\"\n",
    "# remove parentheses from song names\n",
    "clean_song_names = []\n",
    "for name in list(df['name']):\n",
    "    if \"(\" in name:\n",
    "        clean_value = name.split('(')[0][:-1]\n",
    "        clean_song_names.append(clean_value)\n",
    "    else:\n",
    "        clean_song_names.append(name) \n",
    "\n",
    "# update name column with clean values\n",
    "df['name'] = clean_song_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "extract unique value counts from each song,\n",
    "then append to unique_values_df\n",
    "\"\"\"\n",
    "# dataframe container for all unique values\n",
    "unique_values_df = pd.DataFrame()\n",
    "\n",
    "# two lists of song names and artists\n",
    "song_names = list(df['name'])\n",
    "artist_names = list(df['artist'])\n",
    "\n",
    "# initialize lyrics tool\n",
    "l = Lyrics_Tool()\n",
    "\n",
    "# create unique_values_df\n",
    "for i in range(len(song_names)):\n",
    "\n",
    "    # extract one song name & artist\n",
    "    song_name = song_names[i]\n",
    "    artist_name = artist_names[i]\n",
    "    # detect language of song\n",
    "    try:   \n",
    "        # tuple unpack lyrics sample & unique lyric count\n",
    "        lyrics_unique_counts = l.unique_word_count(song_name,artist_name)\n",
    "        words_sample = l.lyrics_sample(song_name,artist_name)\n",
    "\n",
    "        # detect using langdetect\n",
    "        language = detect(words_sample)          \n",
    "    except:\n",
    "        language = 'unknown'\n",
    "    # if current song is english...\n",
    "    if language == 'en':\n",
    "        try:\n",
    "            # add song data to master dataframe\n",
    "            unique_values_df = pd.concat([unique_values_df,lyrics_unique_counts])\n",
    "\n",
    "            # vet each song & update SQL database \n",
    "            l.vet(song_name, artist_name)                  \n",
    "        except:\n",
    "            print('Song not found in Genius database')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# set column names\n",
    "unique_values_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, r'C:\\Users\\wesle\\Desktop\\__MASTER__\\repo_2\\lyrics-analyzer-master\\scripts')\n",
    "\n",
    "# classes\n",
    "from lyrics_tool import Lyrics_Tool\n",
    "\n",
    "\"\"\" \n",
    "this method cleans & joins multiple song datasets, \n",
    "counts how many times each word/lyric occurs. \n",
    "the result is a dataframe containing all unique words, sorted from most common to least common\n",
    "\"\"\"\n",
    "\n",
    "def lyrics_analyzer():  \n",
    "    \n",
    "    # Disable\n",
    "    def blockPrint():\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "    blockPrint()\n",
    "    \n",
    "    \"\"\"\n",
    "    use pandas to read csv files from directory\n",
    "    join all datasets into final df variable\n",
    "    \"\"\"\n",
    "    dataset_folder_path = r'C:\\\\Users\\\\wesle\\\\Desktop\\\\__MASTER__\\repo_2\\lyrics-analyzer-master\\datasets'\n",
    "\n",
    "    dataset_1 = pd.read_csv(dataset_folder_path+'top2018.csv')[['name','artists']]\n",
    "    dataset_1.columns = ['name','artist']\n",
    "\n",
    "    dataset_2 = pd.read_csv(dataset_folder_path+'top50.csv',encoding='latin-1')[['Track.Name','Artist.Name']]\n",
    "    dataset_2.columns = ['name','artist']\n",
    "    \n",
    "    dataset_3 = pd.read_csv(dataset_folder_path+'data.csv')[['song_title','artist']]\n",
    "    dataset_3.columns = ['name','artist']\n",
    "    \n",
    "    dataset_4 = pd.read_csv(dataset_folder_path+'top10s.csv',encoding='latin-1')[['title','artist']]\n",
    "    dataset_4.columns = ['name','artist']\n",
    "    \n",
    "    # join datasets together into one master dataframe\n",
    "    df = pd.concat([dataset_1, dataset_2,dataset_3,dataset_4])\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    clean data\n",
    "    remove parentheses to prevent problems with genius API\n",
    "    \"\"\"\n",
    "    # remove parentheses from song names\n",
    "    clean_song_names = []\n",
    "    for name in list(df['name']):\n",
    "        if \"(\" in name:\n",
    "            clean_value = name.split('(')[0][:-1]\n",
    "            clean_song_names.append(clean_value)\n",
    "        else:\n",
    "            clean_song_names.append(name) \n",
    "\n",
    "    # update name column with clean values\n",
    "    df['name'] = clean_song_names\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    extract unique value counts from each song,\n",
    "    then append to unique_values_df\n",
    "    \"\"\"\n",
    "    # dataframe container for all unique values\n",
    "    unique_values_df = pd.DataFrame()\n",
    "    \n",
    "    # two lists of song names and artists\n",
    "    song_names = list(df['name'])\n",
    "    artist_names = list(df['artist'])\n",
    "    \n",
    "    # initialize lyrics tool\n",
    "    l = LyricsTool()\n",
    "\n",
    "    # create unique_values_df\n",
    "    for i in range(len(song_names)):\n",
    "\n",
    "        # extract one song name & artist\n",
    "        song_name = song_names[i]\n",
    "        artist_name = artist_names[i]\n",
    "        # detect language of song\n",
    "        try:   \n",
    "            # tuple unpack lyrics sample & unique lyric count\n",
    "            lyrics_unique_counts, words_sample = l.lyrics_data(song_name,artist_name)\n",
    "            \n",
    "            # detect using langdetect\n",
    "            language = detect(words_sample)          \n",
    "        except:\n",
    "            language = 'unknown'\n",
    "        # if current song is english...\n",
    "        if language == 'en':\n",
    "            try:\n",
    "                # add song data to master dataframe\n",
    "                unique_values_df = pd.concat([unique_values_df,lyrics_unique_counts])\n",
    "                \n",
    "                # vet each song & update SQL database \n",
    "                l.vet(song_name, artist_name)                  \n",
    "            except:\n",
    "                print('Song not found in Genius database')\n",
    "        else:\n",
    "            pass\n",
    "   \n",
    "    # set column names\n",
    "    unique_values_df.reset_index(inplace=True)\n",
    "    unique_values_df.columns = ['word', 'count']\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    create final summary dataframe\n",
    "    all unique words, sorted from most common to least common\n",
    "    \"\"\"\n",
    "    master_df = pd.DataFrame(columns=['word','count'])  \n",
    "    \n",
    "    # extract all unique words\n",
    "    unique_words = list(unique_values_df['word'].unique())\n",
    "    \n",
    "    for word in unique_words:\n",
    "        # return all rows with the current unique word\n",
    "        data = unique_values_df[unique_values_df['word']==word]\n",
    "        # only 1 instance of current word\n",
    "        if data.shape[0] == 1:\n",
    "            master_df = master_df.append(data)\n",
    "        # multiple instances of current word\n",
    "        else:\n",
    "            # sum values across all songs\n",
    "            word_value = data['word'].iloc[0]\n",
    "            count_value = data['count'].sum() \n",
    "            summed_row = pd.DataFrame([[word_value],[count_value]],index=['word','count']).T\n",
    "            master_df = master_df.append(summed_row)\n",
    "\n",
    "    # reset index\n",
    "    master_df.reset_index(inplace=True)\n",
    "    master_df.drop('index',axis=1,inplace=True)\n",
    "\n",
    "    # sort values\n",
    "    master_df.sort_values(by='count',ascending=False, inplace=True)\n",
    "\n",
    "    # set word column as index\n",
    "    master_df.set_index('word',inplace=True)\n",
    "    \n",
    "    # export csv\n",
    "    master_df.to_csv(dataset_folder_path+\"LyricsAnalysis_1.csv\")\n",
    "\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = lyrics_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "master_df['count'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for explicit lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all rows in dataset\n",
    "for i in range(len(df)):\n",
    "    name = df['name'][i]\n",
    "    artist = df['artist'][i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clever compression of concepts\n",
    "# perctentage clean\n",
    "percent_clean = round(len(df[df['Clean']==1]) / len(df)*100,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
